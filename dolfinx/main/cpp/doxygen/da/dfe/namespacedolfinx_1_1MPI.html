<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>DOLFINx: dolfinx::MPI Namespace Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DOLFINx
   &#160;<span id="projectnumber">0.3.1.0</span>
   </div>
   <div id="projectbrief">DOLFINx C++ interface</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>dolfinx</b></li><li class="navelem"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html">MPI</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">dolfinx::MPI Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> support functionality.  
<a href="../../da/dfe/namespacedolfinx_1_1MPI.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dd/d1d/classdolfinx_1_1MPI_1_1Comm.html">Comm</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A duplicate <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> communicator and manage lifetime of the communicator.  <a href="../../dd/d1d/classdolfinx_1_1MPI_1_1Comm.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../df/ddb/structdolfinx_1_1MPI_1_1dependent__false.html">dependent_false</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:afcd86812aa931ca4c65bcccedc27592d"><td class="memItemLeft" align="right" valign="top"><a id="afcd86812aa931ca4c65bcccedc27592d"></a>enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#afcd86812aa931ca4c65bcccedc27592d">tag</a> : int { <b>consensus_pcx</b>
, <b>consensus_pex</b>
 }</td></tr>
<tr class="memdesc:afcd86812aa931ca4c65bcccedc27592d"><td class="mdescLeft">&#160;</td><td class="mdescRight">MPI communication tags. <br /></td></tr>
<tr class="separator:afcd86812aa931ca4c65bcccedc27592d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ab6a01b5be2487cb6674b70ce6a89bad0"><td class="memItemLeft" align="right" valign="top"><a id="ab6a01b5be2487cb6674b70ce6a89bad0"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#ab6a01b5be2487cb6674b70ce6a89bad0">rank</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:ab6a01b5be2487cb6674b70ce6a89bad0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return process rank for the communicator. <br /></td></tr>
<tr class="separator:ab6a01b5be2487cb6674b70ce6a89bad0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5036b153ca256f285b70638805fd6f3"><td class="memItemLeft" align="right" valign="top"><a id="aa5036b153ca256f285b70638805fd6f3"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aa5036b153ca256f285b70638805fd6f3">size</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:aa5036b153ca256f285b70638805fd6f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return size of the group (number of processes) associated with the communicator. <br /></td></tr>
<tr class="separator:aa5036b153ca256f285b70638805fd6f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07a8824bd71b24c69408e9d91375cb8b"><td class="memTemplParams" colspan="2"><a id="a07a8824bd71b24c69408e9d91375cb8b"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a07a8824bd71b24c69408e9d91375cb8b"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#a07a8824bd71b24c69408e9d91375cb8b">all_to_all</a> (MPI_Comm comm, const <a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt; &amp;send_data)</td></tr>
<tr class="memdesc:a07a8824bd71b24c69408e9d91375cb8b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Send in_values[p0] to process p0 and receive values from process p1 in out_values[p1]. <br /></td></tr>
<tr class="separator:a07a8824bd71b24c69408e9d91375cb8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56a5569af31b6c9a7d55bfd5682ab824"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#a56a5569af31b6c9a7d55bfd5682ab824">compute_graph_edges_pcx</a> (MPI_Comm comm, const xtl::span&lt; const int &gt; &amp;edges)</td></tr>
<tr class="memdesc:a56a5569af31b6c9a7d55bfd5682ab824"><td class="mdescLeft">&#160;</td><td class="mdescRight">Determine incoming graph edges using the PCX consensus algorithm.  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#a56a5569af31b6c9a7d55bfd5682ab824">More...</a><br /></td></tr>
<tr class="separator:a56a5569af31b6c9a7d55bfd5682ab824"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8e8fca883a7cc606d6a9b47734216ab"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#ab8e8fca883a7cc606d6a9b47734216ab">compute_graph_edges_nbx</a> (MPI_Comm comm, const xtl::span&lt; const int &gt; &amp;edges)</td></tr>
<tr class="memdesc:ab8e8fca883a7cc606d6a9b47734216ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Determine incoming graph edges using the NBX consensus algorithm.  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#ab8e8fca883a7cc606d6a9b47734216ab">More...</a><br /></td></tr>
<tr class="separator:ab8e8fca883a7cc606d6a9b47734216ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae40849a1d3e207179bc304f86f94cb6c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae40849a1d3e207179bc304f86f94cb6c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#ae40849a1d3e207179bc304f86f94cb6c">neighbor_all_to_all</a> (MPI_Comm comm, const <a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt; &amp;send_data)</td></tr>
<tr class="memdesc:ae40849a1d3e207179bc304f86f94cb6c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Send in_values[n0] to neighbor process n0 and receive values from neighbor process n1 in out_values[n1].  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#ae40849a1d3e207179bc304f86f94cb6c">More...</a><br /></td></tr>
<tr class="separator:ae40849a1d3e207179bc304f86f94cb6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85afd2323b6d9a3f986abbf5f874f2fc"><td class="memItemLeft" align="right" valign="top">std::array&lt; std::vector&lt; int &gt;, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#a85afd2323b6d9a3f986abbf5f874f2fc">neighbors</a> (MPI_Comm comm)</td></tr>
<tr class="memdesc:a85afd2323b6d9a3f986abbf5f874f2fc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return list of neighbors (sources and destinations) for a neighborhood communicator.  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#a85afd2323b6d9a3f986abbf5f874f2fc">More...</a><br /></td></tr>
<tr class="separator:a85afd2323b6d9a3f986abbf5f874f2fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbce349cf0ea76dd94719d307c17e51b"><td class="memItemLeft" align="right" valign="top">constexpr std::array&lt; std::int64_t, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#afbce349cf0ea76dd94719d307c17e51b">local_range</a> (int <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#ab6a01b5be2487cb6674b70ce6a89bad0">rank</a>, std::int64_t N, int <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aa5036b153ca256f285b70638805fd6f3">size</a>)</td></tr>
<tr class="memdesc:afbce349cf0ea76dd94719d307c17e51b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return local range for given process, splitting [0, N - 1] into <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aa5036b153ca256f285b70638805fd6f3" title="Return size of the group (number of processes) associated with the communicator.">size()</a> portions of almost equal size.  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#afbce349cf0ea76dd94719d307c17e51b">More...</a><br /></td></tr>
<tr class="separator:afbce349cf0ea76dd94719d307c17e51b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cdb48b911eb9e8e02a3921ea641b11c"><td class="memItemLeft" align="right" valign="top">constexpr int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#a8cdb48b911eb9e8e02a3921ea641b11c">index_owner</a> (int <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aa5036b153ca256f285b70638805fd6f3">size</a>, std::size_t index, std::size_t N)</td></tr>
<tr class="memdesc:a8cdb48b911eb9e8e02a3921ea641b11c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return which process owns index (inverse of local_range)  <a href="../../da/dfe/namespacedolfinx_1_1MPI.html#a8cdb48b911eb9e8e02a3921ea641b11c">More...</a><br /></td></tr>
<tr class="separator:a8cdb48b911eb9e8e02a3921ea641b11c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec9dc9db72ab50f3e23e41936e2fe428"><td class="memTemplParams" colspan="2"><a id="aec9dc9db72ab50f3e23e41936e2fe428"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:aec9dc9db72ab50f3e23e41936e2fe428"><td class="memTemplItemLeft" align="right" valign="top">constexpr MPI_Datatype&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aec9dc9db72ab50f3e23e41936e2fe428">mpi_type</a> ()</td></tr>
<tr class="memdesc:aec9dc9db72ab50f3e23e41936e2fe428"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> Type. <br /></td></tr>
<tr class="separator:aec9dc9db72ab50f3e23e41936e2fe428"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> support functionality. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="ab8e8fca883a7cc606d6a9b47734216ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab8e8fca883a7cc606d6a9b47734216ab">&#9670;&nbsp;</a></span>compute_graph_edges_nbx()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int &gt; compute_graph_edges_nbx </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const xtl::span&lt; const int &gt; &amp;&#160;</td>
          <td class="paramname"><em>edges</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Determine incoming graph edges using the NBX consensus algorithm. </p>
<p>Given a list of outgoing edges (destination ranks) from this rank, this function returns the incoming edges (source ranks) to this rank.</p>
<dl class="section note"><dt>Note</dt><dd>This function is for sparse communication patterns, i.e. where the number of ranks that communicate with each other is relatively small. It is scalable, i.e. no arrays the size of the communicator are constructed and the communication pattern is sparse. It implements the NBX algorithm presented in <a href="https://dx.doi.org/10.1145/1837853.1693476">https://dx.doi.org/10.1145/1837853.1693476</a>.</dd>
<dd>
For sparse graphs, this function has \(O(\log p)\) cost, where \(p\)is the number of <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> ranks. It is suitable for modest <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> rank counts.</dd>
<dd>
Collective over ranks that are connected by graph edge.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> communicator </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">edges</td><td>Edges (ranks) from this rank (the caller). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Ranks that have defined edges from them to this rank. </dd></dl>

</div>
</div>
<a id="a56a5569af31b6c9a7d55bfd5682ab824"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56a5569af31b6c9a7d55bfd5682ab824">&#9670;&nbsp;</a></span>compute_graph_edges_pcx()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int &gt; compute_graph_edges_pcx </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const xtl::span&lt; const int &gt; &amp;&#160;</td>
          <td class="paramname"><em>edges</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Determine incoming graph edges using the PCX consensus algorithm. </p>
<p>Given a list of outgoing edges (destination ranks) from this rank, this function returns the incoming edges (source ranks) to this rank.</p>
<dl class="section note"><dt>Note</dt><dd>This function is for sparse communication patterns, i.e. where the number of ranks that communicate with each other is relatively small. It <b>is not</b> scalable as arrays the size of the communicator are allocated. It implements the PCX algorithm described in <a href="https://dx.doi.org/10.1145/1837853.1693476">https://dx.doi.org/10.1145/1837853.1693476</a>.</dd>
<dd>
For sparse graphs, this function has \(O(p)\) cost, where \(p\)is the number of <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> ranks. It is suitable for modest <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> rank counts.</dd>
<dd>
Collective</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> communicator </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">edges</td><td>Edges (ranks) from this rank (the caller). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Ranks that have defined edges from them to this rank. </dd></dl>

</div>
</div>
<a id="a8cdb48b911eb9e8e02a3921ea641b11c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cdb48b911eb9e8e02a3921ea641b11c">&#9670;&nbsp;</a></span>index_owner()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr int dolfinx::MPI::index_owner </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>N</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return which process owns index (inverse of local_range) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">size</td><td>Number of <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> ranks </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">index</td><td>The index to determine owning rank </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">N</td><td>Total number of indices </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The rank of the owning process </dd></dl>

</div>
</div>
<a id="afbce349cf0ea76dd94719d307c17e51b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afbce349cf0ea76dd94719d307c17e51b">&#9670;&nbsp;</a></span>local_range()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr std::array&lt;std::int64_t, 2&gt; dolfinx::MPI::local_range </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::int64_t&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return local range for given process, splitting [0, N - 1] into <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html#aa5036b153ca256f285b70638805fd6f3" title="Return size of the group (number of processes) associated with the communicator.">size()</a> portions of almost equal size. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">rank</td><td><a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> rank of the caller </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">N</td><td>The value to partition </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">size</td><td>The number of <a class="el" href="../../da/dfe/namespacedolfinx_1_1MPI.html" title="MPI support functionality.">MPI</a> ranks across which to partition <code>N</code> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae40849a1d3e207179bc304f86f94cb6c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae40849a1d3e207179bc304f86f94cb6c">&#9670;&nbsp;</a></span>neighbor_all_to_all()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt; neighbor_all_to_all </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html">graph::AdjacencyList</a>&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>send_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Send in_values[n0] to neighbor process n0 and receive values from neighbor process n1 in out_values[n1]. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td>Neighborhood communicator </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">send_data</td><td>The data to send to each rank. <a class="el" href="../../df/d84/classdolfinx_1_1graph_1_1AdjacencyList.html#aa4ac382c064efdb8446805135773b734" title="Get the number of nodes.">graph::AdjacencyList&lt;T&gt;::num_nodes</a> should be equal to the number of neighbourhood out edges. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Data received from incoming neighbourhood ranks. </dd></dl>

</div>
</div>
<a id="a85afd2323b6d9a3f986abbf5f874f2fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85afd2323b6d9a3f986abbf5f874f2fc">&#9670;&nbsp;</a></span>neighbors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::array&lt; std::vector&lt; int &gt;, 2 &gt; neighbors </td>
          <td>(</td>
          <td class="paramtype">MPI_Comm&#160;</td>
          <td class="paramname"><em>comm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Return list of neighbors (sources and destinations) for a neighborhood communicator. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td>Neighborhood communicator </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>source ranks [0], destination ranks [1] </dd></dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
